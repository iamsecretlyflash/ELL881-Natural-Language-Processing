{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('/Users/anamikaseth/Downloads/test_stripped.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['span_start_index'] = ['[0]']*len(test_data)\n",
    "test_data['span_end_index'] = ['[1]']*len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.to_csv('/Users/anamikaseth/Downloads/test_stripped.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>claim_label</th>\n",
       "      <th>span_start_index</th>\n",
       "      <th>span_end_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['And', ' it', ' should', ' be', ' noted', ' t...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['China', ' has', ' nearly', ' won', ' WWIII',...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['the', ' democrats', ' want', ' a', ' market'...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['Carry', ' aerosol', ' lysol', '\\nAnyone', ' ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['According', ' with', ' Dr', ' Luis', ' Aguir...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tokens  claim_label  \\\n",
       "0  ['And', ' it', ' should', ' be', ' noted', ' t...            1   \n",
       "1  ['China', ' has', ' nearly', ' won', ' WWIII',...            1   \n",
       "2  ['the', ' democrats', ' want', ' a', ' market'...            1   \n",
       "3  ['Carry', ' aerosol', ' lysol', '\\nAnyone', ' ...            1   \n",
       "4  ['According', ' with', ' Dr', ' Luis', ' Aguir...            1   \n",
       "\n",
       "  span_start_index span_end_index  \n",
       "0              [0]            [1]  \n",
       "1              [0]            [1]  \n",
       "2              [0]            [1]  \n",
       "3              [0]            [1]  \n",
       "4              [0]            [1]  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def getPredictions(y_val, preds, mapList):\n",
    "    \n",
    "    groundTruth = []\n",
    "    predictedIdx = []\n",
    "    bioGround = []\n",
    "    bioPreds = []\n",
    "    #if any a subword lies in span - the word is in span\n",
    "    for dp in range(len(y_val)):\n",
    "        curG = []\n",
    "        curP = []\n",
    "        curBIO = []\n",
    "        curBIOG = []\n",
    "        for i in mapList[dp].keys():\n",
    "            containsI_ground = False\n",
    "            containsI_pred = False\n",
    "            isBegin = False\n",
    "            isBeginG = False\n",
    "            for k in mapList[dp][i]:\n",
    "                if (y_val[dp][k] >= 2):  #subword is I or B\n",
    "                    containsI_ground = True\n",
    "                    if (y_val[dp][k] == 3):\n",
    "                        isBeginG = True\n",
    "                if (preds[dp][k] >= 2):  #subword is I or B\n",
    "                    containsI_pred = True\n",
    "                    if (y_val[dp][k] == 3):\n",
    "                        isBegin = True\n",
    "                break           # We only consider first subword label in deciding the word level label\n",
    "\n",
    "            if (containsI_ground):\n",
    "                curG.append(i)\n",
    "                if (isBeginG):\n",
    "                    curBIOG.append(1) #B\n",
    "                else:\n",
    "                    curBIOG.append(2) #I\n",
    "            else:\n",
    "                curBIOG.append(0) #O\n",
    "            if (containsI_pred):\n",
    "                if (isBegin):\n",
    "                    curBIO.append(1) #B\n",
    "                else:\n",
    "                    curBIO.append(2) #I\n",
    "                curP.append(i)\n",
    "            else:\n",
    "                curBIO.append(0) #O\n",
    "\n",
    "        groundTruth.append(curG)\n",
    "        predictedIdx.append(curP)\n",
    "        bioPreds.append(curBIO)\n",
    "        bioGround.append(curBIOG)\n",
    "    return groundTruth, predictedIdx, bioGround, bioPreds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1144 \n",
      "1915 \n",
      "1185 \n",
      "251521"
     ]
    }
   ],
   "source": [
    "s = \"and so are you\"\n",
    "\n",
    "for i in s:\n",
    "    if i !=' ':\n",
    "     print(ord(i)-ord('a')+1,end = '')\n",
    "    else:\n",
    "        print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
